{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>This notebook when run will produce a module which predicts the chance of death of patients in ICU after 24 hours</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# visualizatoin \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "# data preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "from fairlearn.reductions import *\n",
    "from fairlearn.metrics import *\n",
    "\n",
    "\n",
    "\n",
    "#learning\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "#post-processing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   encounter_id  patient_id  hospital_id  hospital_death   age    bmi   \n0         66154       25312          118               0  68.0  22.73  \\\n1        114252       59342           81               0  77.0  27.42   \n2        119783       50777          118               0  25.0  31.95   \n3         79267       46918          118               0  81.0  22.64   \n4         92056       34377           33               0  19.0    NaN   \n\n   elective_surgery  ethnicity gender  height  ... aids cirrhosis   \n0                 0  Caucasian      M   180.3  ...  0.0       0.0  \\\n1                 0  Caucasian      F   160.0  ...  0.0       0.0   \n2                 0  Caucasian      F   172.7  ...  0.0       0.0   \n3                 1  Caucasian      F   165.1  ...  0.0       0.0   \n4                 0  Caucasian      M   188.0  ...  0.0       0.0   \n\n   diabetes_mellitus hepatic_failure immunosuppression  leukemia  lymphoma   \n0                1.0             0.0               0.0       0.0       0.0  \\\n1                1.0             0.0               0.0       0.0       0.0   \n2                0.0             0.0               0.0       0.0       0.0   \n3                0.0             0.0               0.0       0.0       0.0   \n4                0.0             0.0               0.0       0.0       0.0   \n\n   solid_tumor_with_metastasis  apache_3j_bodysystem  apache_2_bodysystem  \n0                          0.0                Sepsis       Cardiovascular  \n1                          0.0           Respiratory          Respiratory  \n2                          0.0             Metabolic            Metabolic  \n3                          0.0        Cardiovascular       Cardiovascular  \n4                          0.0                Trauma               Trauma  \n\n[5 rows x 186 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>encounter_id</th>\n      <th>patient_id</th>\n      <th>hospital_id</th>\n      <th>hospital_death</th>\n      <th>age</th>\n      <th>bmi</th>\n      <th>elective_surgery</th>\n      <th>ethnicity</th>\n      <th>gender</th>\n      <th>height</th>\n      <th>...</th>\n      <th>aids</th>\n      <th>cirrhosis</th>\n      <th>diabetes_mellitus</th>\n      <th>hepatic_failure</th>\n      <th>immunosuppression</th>\n      <th>leukemia</th>\n      <th>lymphoma</th>\n      <th>solid_tumor_with_metastasis</th>\n      <th>apache_3j_bodysystem</th>\n      <th>apache_2_bodysystem</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>66154</td>\n      <td>25312</td>\n      <td>118</td>\n      <td>0</td>\n      <td>68.0</td>\n      <td>22.73</td>\n      <td>0</td>\n      <td>Caucasian</td>\n      <td>M</td>\n      <td>180.3</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Sepsis</td>\n      <td>Cardiovascular</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>114252</td>\n      <td>59342</td>\n      <td>81</td>\n      <td>0</td>\n      <td>77.0</td>\n      <td>27.42</td>\n      <td>0</td>\n      <td>Caucasian</td>\n      <td>F</td>\n      <td>160.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Respiratory</td>\n      <td>Respiratory</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>119783</td>\n      <td>50777</td>\n      <td>118</td>\n      <td>0</td>\n      <td>25.0</td>\n      <td>31.95</td>\n      <td>0</td>\n      <td>Caucasian</td>\n      <td>F</td>\n      <td>172.7</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Metabolic</td>\n      <td>Metabolic</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>79267</td>\n      <td>46918</td>\n      <td>118</td>\n      <td>0</td>\n      <td>81.0</td>\n      <td>22.64</td>\n      <td>1</td>\n      <td>Caucasian</td>\n      <td>F</td>\n      <td>165.1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Cardiovascular</td>\n      <td>Cardiovascular</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>92056</td>\n      <td>34377</td>\n      <td>33</td>\n      <td>0</td>\n      <td>19.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>Caucasian</td>\n      <td>M</td>\n      <td>188.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Trauma</td>\n      <td>Trauma</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 186 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# description\n",
    "description = pd.read_csv('data/WiDS_Datathon_2020_Dictionary.csv')\n",
    "description_dict = description.set_index('Variable Name').to_dict(orient='index')\n",
    "# data\n",
    "df = pd.read_csv('data/training_v2.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pre-processing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2 # proportion for train versus test+val split\n",
    "val_size = 0.5 # proportion for test versus valsplit\n",
    "random_state = 42  # random state is used to set a seed for randomness, which is only relevant for reproducibility purposes\n",
    "max_missing = 0.8  # maximum percentage of missing values for a column to be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aertbei/Repos/2IX30_17/venv/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "ColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('constant',\n                                                  VarianceThreshold()),\n                                                 ('imputer',\n                                                  SimpleImputer(strategy='median'))]),\n                                 <sklearn.compose._column_transformer.make_column_selector object at 0x7f451c316aa0>),\n                                ('cat',\n                                 Pipeline(steps=[('encoder',\n                                                  OneHotEncoder(drop='first',\n                                                                handle_unknown='ignore',\n                                                                sparse=False))]),\n                                 <sklearn.compose._column_transformer.make_column_selector object at 0x7f451c316a10>)])",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n                                 Pipeline(steps=[(&#x27;constant&#x27;,\n                                                  VarianceThreshold()),\n                                                 (&#x27;imputer&#x27;,\n                                                  SimpleImputer(strategy=&#x27;median&#x27;))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f451c316aa0&gt;),\n                                (&#x27;cat&#x27;,\n                                 Pipeline(steps=[(&#x27;encoder&#x27;,\n                                                  OneHotEncoder(drop=&#x27;first&#x27;,\n                                                                handle_unknown=&#x27;ignore&#x27;,\n                                                                sparse=False))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f451c316a10&gt;)])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n                                 Pipeline(steps=[(&#x27;constant&#x27;,\n                                                  VarianceThreshold()),\n                                                 (&#x27;imputer&#x27;,\n                                                  SimpleImputer(strategy=&#x27;median&#x27;))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f451c316aa0&gt;),\n                                (&#x27;cat&#x27;,\n                                 Pipeline(steps=[(&#x27;encoder&#x27;,\n                                                  OneHotEncoder(drop=&#x27;first&#x27;,\n                                                                handle_unknown=&#x27;ignore&#x27;,\n                                                                sparse=False))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f451c316a10&gt;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f451c316aa0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VarianceThreshold</label><div class=\"sk-toggleable__content\"><pre>VarianceThreshold()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f451c316a10&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 5.85s\n",
      "Train set: 73370 rows, 217 columns\n",
      "Validation set: 9171 rows, 217 columns\n",
      "Test set: 9172 rows, 217 columns\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# save features\n",
    "X = df.copy().drop(['hospital_death', 'patient_id', 'encounter_id', 'hospital_id', 'icu_id', # drop identifiers\n",
    "                    'apache_4a_hospital_death_prob', 'apache_4a_icu_death_prob', # drop APACHE scores\n",
    "                    'apache_2_bodysystem', 'bmi'], # drop because of similarity with apache_3j_bodysystem\n",
    "                   axis=1)\n",
    "# save target variable\n",
    "y = df['hospital_death'].copy()\n",
    "# save APACHE scores for later evaluation on train / test / validation data\n",
    "y_apache = df['apache_4a_hospital_death_prob'].copy()\n",
    "\n",
    "\"\"\" SPLIT DATA SET \"\"\"\n",
    "# split the dataset into train and test+validation set\n",
    "(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    y_apache_train,\n",
    "    y_apache_test,\n",
    "    ) = train_test_split(X, y, y_apache, \n",
    "                         test_size=test_size, # used for testing and validation\n",
    "                         random_state=random_state # for reproducibility\n",
    "                        ) \n",
    "# split the test set into test + validation set\n",
    "(\n",
    "    X_val,\n",
    "    X_test,\n",
    "    y_val,\n",
    "    y_test,\n",
    "    y_apache_val,\n",
    "    y_apache_test,\n",
    "    ) = train_test_split(X_test, y_test, y_apache_test, \n",
    "                         test_size=val_size, # used for testing and validation\n",
    "                         random_state=random_state # for reproducibility\n",
    "                        ) \n",
    "\n",
    "# \"\"\"MISSING VALUES\"\"\"\n",
    "# # drop columns with many missing values\n",
    "# missing = X_train.isna().sum() > max_missing * len(X_train)\n",
    "# missing = missing[missing].index\n",
    "# X_train = X_train.drop(missing, axis=1)\n",
    "# X_val = X_val.drop(missing, axis=1)\n",
    "# X_test = X_test.drop(missing, axis=1)\n",
    "\n",
    "\"\"\"FURTHER PROCESSING PIPELINE\"\"\"\n",
    "# define pre-processing steps for numerical features\n",
    "num_transformer = Pipeline(steps=[(\"constant\", VarianceThreshold()), # remove constant features\n",
    "                                  (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                                 ])\n",
    "# define preprocessing steps for categorical features\n",
    "cat_transformer = Pipeline(steps=[(\"encoder\", OneHotEncoder(drop='first', sparse=False, handle_unknown=\"ignore\"))])\n",
    "# create preprocessing pipeline\n",
    "prep_pipeline = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, make_column_selector(dtype_exclude=object)), # apply to columns NOT of type object (int or float)\n",
    "        ('cat', cat_transformer, make_column_selector(dtype_include=object)) # apply to columns of type object\n",
    "    ])\n",
    "# pipeline\n",
    "prep_pipeline.fit(X_train, y_train)\n",
    "display(prep_pipeline) # disply preprocessing pipeline\n",
    "\n",
    "# transform data sets\n",
    "X_train = pd.DataFrame(prep_pipeline.transform(X_train), columns=prep_pipeline.get_feature_names_out())\n",
    "X_val = pd.DataFrame(prep_pipeline.transform(X_val), columns=prep_pipeline.get_feature_names_out())\n",
    "X_test = pd.DataFrame(prep_pipeline.transform(X_test), columns=prep_pipeline.get_feature_names_out())\n",
    "        \n",
    "\"\"\"PRINT STATS\"\"\"\n",
    "print(\"Time: %.2fs\" % (time.time() - start_time))\n",
    "print(\"Train set: %s rows, %s columns\" % X_train.shape)\n",
    "print(\"Validation set: %s rows, %s columns\" % X_val.shape)\n",
    "print(\"Test set: %s rows, %s columns\" % X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boruta implementation based on original code from (source here)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#checking feature importance from boruta\n",
    "X_boruta = X_train.values\n",
    "Y_boruta = y_train.values\n",
    "\n",
    "# define random forest classifier, with utilising all cores and\n",
    "# sampling in proportion to y labels\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=10)\n",
    "# define Boruta feature selection method\n",
    "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=1)\n",
    "# find all relevant features - 5 features should be selected\n",
    "feat_selector.fit(X_boruta, Y_boruta)\n",
    "# check selected features - first 5 features are selected\n",
    "feat_selector.support_\n",
    "# check ranking of features\n",
    "feat_selector.ranking_\n",
    "# call transform() on X to filter it down to selected features\n",
    "X_filtered = feat_selector.transform(X_boruta)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a cross-validation method (Modified from [author here])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross-Validation\n",
    "#taken from https://www.section.io/engineering-education/how-to-implement-k-fold-cross-validation/\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def cross_validation(model, _X, _y, _cv=5):\n",
    "      '''Function to perform 5 Folds Cross-Validation\n",
    "       Parameters\n",
    "       ----------\n",
    "      model: Python Class, default=None\n",
    "              This is the machine learning algorithm to be used for training.\n",
    "      _X: array\n",
    "           This is the matrix of features.\n",
    "      _y: array\n",
    "           This is the target variable.\n",
    "      _cv: int, default=5\n",
    "          Determines the number of folds for cross-validation.\n",
    "       Returns\n",
    "       -------\n",
    "       The function returns a dictionary containing the metrics 'accuracy', 'precision',\n",
    "       'recall', 'f1' for both training set and validation set.\n",
    "      '''\n",
    "      _scoring = ['accuracy', 'roc_auc']\n",
    "      results = cross_validate(estimator=model,\n",
    "                               X=_X,\n",
    "                               y=_y,\n",
    "                               cv=_cv,\n",
    "                               scoring=_scoring,\n",
    "                               return_train_score=True)\n",
    "      \n",
    "      return {\"Training Accuracy scores\": results['train_accuracy'],\n",
    "              \"Mean Training Accuracy\": results['train_accuracy'].mean()*100,\n",
    "              \"Training AUC scores\": results['train_roc_auc'],\n",
    "              \"Mean Training AUC score\": results['train_roc_auc'].mean(),\n",
    "              \"Validation Accuracy scores\": results['test_accuracy'],\n",
    "              \"Mean Validation Accuracy\": results['test_accuracy'].mean()*100,\n",
    "              \"Validation AUC Scores\": results['test_roc_auc'],\n",
    "              \"Mean Validation AUC score\": results['test_roc_auc'].mean()\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "borutacolumns = ['num__age', 'num__elective_surgery', 'num__pre_icu_los_days',\n",
    "       'num__weight', 'num__albumin_apache', 'num__apache_2_diagnosis',\n",
    "       'num__apache_3j_diagnosis', 'num__apache_post_operative',\n",
    "       'num__bilirubin_apache', 'num__bun_apache',\n",
    "       'num__creatinine_apache', 'num__fio2_apache',\n",
    "       'num__gcs_eyes_apache', 'num__gcs_motor_apache',\n",
    "       'num__gcs_verbal_apache', 'num__glucose_apache',\n",
    "       'num__heart_rate_apache', 'num__hematocrit_apache',\n",
    "       'num__intubated_apache', 'num__map_apache', 'num__paco2_apache',\n",
    "       'num__paco2_for_ph_apache', 'num__pao2_apache', 'num__ph_apache',\n",
    "       'num__resprate_apache', 'num__temp_apache',\n",
    "       'num__urineoutput_apache', 'num__ventilated_apache',\n",
    "       'num__wbc_apache', 'num__d1_diasbp_min',\n",
    "       'num__d1_diasbp_noninvasive_min', 'num__d1_heartrate_max',\n",
    "       'num__d1_heartrate_min', 'num__d1_mbp_invasive_min',\n",
    "       'num__d1_mbp_max', 'num__d1_mbp_min',\n",
    "       'num__d1_mbp_noninvasive_max', 'num__d1_mbp_noninvasive_min',\n",
    "       'num__d1_resprate_max', 'num__d1_resprate_min', 'num__d1_spo2_min',\n",
    "       'num__d1_sysbp_invasive_min', 'num__d1_sysbp_max',\n",
    "       'num__d1_sysbp_min', 'num__d1_sysbp_noninvasive_max',\n",
    "       'num__d1_sysbp_noninvasive_min', 'num__d1_temp_max',\n",
    "       'num__d1_temp_min', 'num__h1_diasbp_min',\n",
    "       'num__h1_diasbp_noninvasive_min', 'num__h1_heartrate_max',\n",
    "       'num__h1_heartrate_min', 'num__h1_mbp_min',\n",
    "       'num__h1_mbp_noninvasive_min', 'num__h1_resprate_max',\n",
    "       'num__h1_resprate_min', 'num__h1_spo2_min', 'num__h1_sysbp_max',\n",
    "       'num__h1_sysbp_min', 'num__h1_sysbp_noninvasive_max',\n",
    "       'num__h1_sysbp_noninvasive_min', 'num__h1_temp_max',\n",
    "       'num__h1_temp_min', 'num__d1_albumin_max', 'num__d1_albumin_min',\n",
    "       'num__d1_bilirubin_max', 'num__d1_bilirubin_min',\n",
    "       'num__d1_bun_max', 'num__d1_bun_min', 'num__d1_calcium_min',\n",
    "       'num__d1_creatinine_max', 'num__d1_creatinine_min',\n",
    "       'num__d1_glucose_max', 'num__d1_glucose_min', 'num__d1_hco3_max',\n",
    "       'num__d1_hco3_min', 'num__d1_hemaglobin_max',\n",
    "       'num__d1_hemaglobin_min', 'num__d1_hematocrit_max',\n",
    "       'num__d1_hematocrit_min', 'num__d1_inr_max', 'num__d1_inr_min',\n",
    "       'num__d1_lactate_max', 'num__d1_lactate_min',\n",
    "       'num__d1_platelets_max', 'num__d1_platelets_min',\n",
    "       'num__d1_sodium_max', 'num__d1_wbc_max', 'num__d1_wbc_min',\n",
    "       'num__h1_glucose_min', 'num__h1_inr_max', 'num__h1_inr_min',\n",
    "       'num__d1_arterial_pco2_max', 'num__d1_arterial_pco2_min',\n",
    "       'num__d1_arterial_ph_max', 'num__d1_arterial_ph_min',\n",
    "       'num__d1_arterial_po2_max', 'num__d1_arterial_po2_min',\n",
    "       'num__d1_pao2fio2ratio_max', 'num__d1_pao2fio2ratio_min',\n",
    "       'cat__hospital_admit_source_Operating Room',\n",
    "       'cat__icu_admit_source_Operating Room / Recovery',\n",
    "       'cat__apache_3j_bodysystem_Metabolic']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_df = pd.DataFrame(X_train, columns=X_train.columns[borutacolumns]) #feat_selector..support_\n",
    "# X_val_df = pd.DataFrame(X_val, columns=X_val.columns[borutacolumns])\n",
    "\n",
    "X_train_df = X_train[borutacolumns]\n",
    "X_val_df = X_val[borutacolumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train_df)\n",
    "val_data = lgb.Dataset(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 100, 'objective': 'binary'}\n",
    "param['metric'] = 'auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint = ErrorRateParity(difference_bound=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_features = X_train_df[[\"num__age\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "ExponentiatedGradient(constraints=<fairlearn.reductions._moments.utility_parity.ErrorRateParity object at 0x7f450afa3af0>,\n                      estimator=LGBMClassifier(class_weight='balanced',\n                                               num_leaves=500),\n                      nu=1.180337467640127e-05)",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExponentiatedGradient(constraints=&lt;fairlearn.reductions._moments.utility_parity.ErrorRateParity object at 0x7f450afa3af0&gt;,\n                      estimator=LGBMClassifier(class_weight=&#x27;balanced&#x27;,\n                                               num_leaves=500),\n                      nu=1.180337467640127e-05)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExponentiatedGradient</label><div class=\"sk-toggleable__content\"><pre>ExponentiatedGradient(constraints=&lt;fairlearn.reductions._moments.utility_parity.ErrorRateParity object at 0x7f450afa3af0&gt;,\n                      estimator=LGBMClassifier(class_weight=&#x27;balanced&#x27;,\n                                               num_leaves=500),\n                      nu=1.180337467640127e-05)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, num_leaves=500)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, num_leaves=500)</pre></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a gradient based tree with 100 leaves \n",
    "modelLight = lgb.LGBMClassifier(num_leaves=500, class_weight=\"balanced\")\n",
    "reduction = ExponentiatedGradient(modelLight, constraint)\n",
    "reduction.fit(X_train_df, y_train, sensitive_features=sensitive_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross-val with sklearn api for gradient based\n",
    "cross_validation(reduction, X_train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "modelLightCal = CalibratedClassifierCV(reduction)\n",
    "modelLightCal.fit(X_train_df, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-processing basic explainations only for 1 run of CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "predicted= reduction.predict(X_val_df)\n",
    "\n",
    "conf_mat = confusion_matrix(y_val, predicted)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(conf_mat)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction.predict_proba(X_val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV, CalibrationDisplay\n",
    "\n",
    "clf_list = [\n",
    "    (reduction, \"LightGBM\"),\n",
    "]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "gs = GridSpec(4, 2)\n",
    "colors = plt.cm.get_cmap(\"Dark2\")\n",
    "\n",
    "ax_calibration_curve = fig.add_subplot(gs[:2, :2])\n",
    "calibration_displays = {}\n",
    "for i, (clf, name) in enumerate(clf_list):\n",
    "    clf.fit(X_train_df, y_train)\n",
    "    display = CalibrationDisplay.from_estimator(\n",
    "        clf,\n",
    "        X_val_df,\n",
    "        y_val,\n",
    "        n_bins=10,\n",
    "        name=name,\n",
    "        ax=ax_calibration_curve,\n",
    "        color=colors(i),\n",
    "    )\n",
    "    calibration_displays[name] = display\n",
    "\n",
    "ax_calibration_curve.grid()\n",
    "ax_calibration_curve.set_title(\"Calibration plots\")\n",
    "\n",
    "# Add histogram\n",
    "grid_positions = [(2, 0), (2, 1), (3, 0), (3, 1)]\n",
    "for i, (_, name) in enumerate(clf_list):\n",
    "    row, col = grid_positions[i]\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "\n",
    "    ax.hist(\n",
    "        calibration_displays[name].y_prob,\n",
    "        range=(0, 1),\n",
    "        bins=10,\n",
    "        label=name,\n",
    "        color=colors(i),\n",
    "    )\n",
    "    ax.set(title=name, xlabel=\"Mean predicted probability\", ylabel=\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we create an empty dict to be used to store metrics\n",
    "eval_res = {}\n",
    "\n",
    "\n",
    "#this is one implementation of LightGBM used for post-process visualization, the actual model uses a sklearn API of LightGBM\n",
    "bst = lgb.train(param, train_data, 100, valid_sets=[val_data, train_data], callbacks=[lgb.record_evaluation(eval_res)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#this will not run unless graphviz is installed in the direction shown below\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz/bin/'\n",
    "\n",
    "lgb.plot_tree(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lgb.plot_metric(booster=eval_res, metric='auc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
